<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Diego Iturrieta" />

<meta name="date" content="2025-04-15" />

<title>Cuaderno con Conceptos de IA</title>

<script src="MD-Glosario-de-Conceptos_files/header-attrs-2.25/header-attrs.js"></script>
<script src="MD-Glosario-de-Conceptos_files/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="MD-Glosario-de-Conceptos_files/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="MD-Glosario-de-Conceptos_files/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="MD-Glosario-de-Conceptos_files/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="MD-Glosario-de-Conceptos_files/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="MD-Glosario-de-Conceptos_files/navigation-1.1/tabsets.js"></script>
<link href="MD-Glosario-de-Conceptos_files/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="MD-Glosario-de-Conceptos_files/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>



<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div id="header">



<h1 class="title toc-ignore">Cuaderno con Conceptos de IA</h1>
<h4 class="author">Diego Iturrieta</h4>
<h4 class="date">2025-04-15</h4>

</div>


<div
id="glosario-prÃ¡ctico-y-conceptual-sobre-llms-para-investigadores-sociales"
class="section level1">
<h1>ğŸ“˜ Glosario PrÃ¡ctico y Conceptual sobre LLMs para Investigadores
Sociales</h1>
<p>Este glosario tiene como objetivo entregar definiciones claras,
ejemplos aplicados al anÃ¡lisis discursivo, y fundamentos prÃ¡cticos para
comprender el uso de modelos de lenguaje de gran tamaÃ±o (LLMs) en
investigaciÃ³n polÃ­tica y social.</p>
<hr />
<div id="conceptos-fundamentales" class="section level2">
<h2>ğŸ”‘ Conceptos Fundamentales</h2>
<div id="llm-large-language-model" class="section level3">
<h3>ğŸ§  LLM (Large Language Model)</h3>
<p><strong>DefiniciÃ³n:</strong><br />
Modelo de lenguaje con miles de millones de parÃ¡metros, entrenado sobre
grandes corpus de texto para entender y generar lenguaje natural.</p>
<p><strong>Ejemplo en polÃ­tica:</strong><br />
Puedes usar un LLM como LLaMA 3.1 para clasificar discursos de alcaldes
segÃºn si promueven ideas de â€œmano duraâ€ o no.</p>
<hr />
</div>
<div id="parÃ¡metros" class="section level3">
<h3>ğŸ§® ParÃ¡metros</h3>
<p><strong>DefiniciÃ³n:</strong><br />
Son los â€œpesosâ€ que el modelo ajusta durante su entrenamiento.
Determinan cÃ³mo el modelo interpreta el texto.</p>
<p><strong>Ejemplo:</strong><br />
LLaMA 3.1 de 4B tiene 4.000 millones de parÃ¡metros. Modelos mÃ¡s grandes
como GPT-3 pueden tener 175B.</p>
<hr />
</div>
<div id="inferencia" class="section level3">
<h3>ğŸ—£ï¸ Inferencia</h3>
<p><strong>DefiniciÃ³n:</strong><br />
Fase en la que usas el modelo ya entrenado para predecir, clasificar o
generar texto.</p>
<p><strong>Ejemplo:</strong><br />
Cuando pasas un discurso al modelo y te responde: â€œSÃ­, este discurso
promueve polÃ­ticas punitivasâ€, estÃ¡s haciendo inferencia.</p>
<hr />
</div>
<div id="fine-tuning" class="section level3">
<h3>ğŸ”„ Fine-tuning</h3>
<p><strong>DefiniciÃ³n:</strong><br />
Reentrenar un modelo preexistente con tus propios datos para que se
adapte a un dominio o tarea especÃ­fica.</p>
<p><strong>Ejemplo:</strong><br />
Usar 300 discursos etiquetados por ti para ajustar LLaMA y que aprenda a
reconocer con mÃ¡s precisiÃ³n ideas de â€œmilitarizaciÃ³nâ€.</p>
<hr />
</div>
</div>
<div id="componentes-del-proceso" class="section level2">
<h2>ğŸ“¦ Componentes del Proceso</h2>
<div id="token" class="section level3">
<h3>ğŸ“„ Token</h3>
<p><strong>DefiniciÃ³n:</strong><br />
Unidad mÃ­nima de texto que el modelo entiende. Puede ser una palabra,
parte de una palabra o incluso signos de puntuaciÃ³n.</p>
<p><strong>Ejemplo:</strong><br />
â€œSeguridad pÃºblicaâ€ puede dividirse en tokens como [â€œSegâ€, â€œuridadâ€, â€
pÃºblicaâ€] dependiendo del modelo.</p>
<hr />
</div>
<div id="embedding" class="section level3">
<h3>ğŸ“ Embedding</h3>
<p><strong>DefiniciÃ³n:</strong><br />
RepresentaciÃ³n numÃ©rica de un texto (token, frase, oraciÃ³n) en un
espacio vectorial. Permite comparar semÃ¡nticamente distintos textos.</p>
<p><strong>Ejemplo:</strong><br />
Dos discursos con ideas similares tendrÃ¡n embeddings cercanos entre sÃ­,
lo que permite hacer clustering.</p>
<hr />
</div>
<div id="attention" class="section level3">
<h3>ğŸ§  Attention</h3>
<p><strong>DefiniciÃ³n:</strong><br />
Mecanismo que permite al modelo â€œponer atenciÃ³nâ€ en partes relevantes
del texto cuando procesa una palabra.</p>
<p><strong>Ejemplo:</strong><br />
En la frase â€œLa alcaldesa propuso aumentar la dotaciÃ³n policialâ€, el
modelo presta atenciÃ³n a â€œaumentarâ€ y â€œpolicialâ€ para entender el foco
del discurso.</p>
<hr />
</div>
<div id="transformer" class="section level3">
<h3>ğŸ§© Transformer</h3>
<p><strong>DefiniciÃ³n:</strong><br />
Arquitectura base de casi todos los LLMs actuales. Introducida en el
paper â€œAttention is All You Needâ€.</p>
<p><strong>Ejemplo:</strong><br />
GPT, BERT y LLaMA son todos modelos basados en transformers.</p>
<hr />
</div>
<div id="prompt" class="section level3">
<h3>ğŸ—‚ï¸ Prompt</h3>
<p><strong>DefiniciÃ³n:</strong><br />
InstrucciÃ³n o entrada que das al modelo para obtener una respuesta.</p>
<p><strong>Ejemplo:</strong><br />
Prompt simple:<br />
&gt; â€œClasifica el siguiente discurso segÃºn si usa una narrativa de mano
dura: {discurso}â€</p>
<hr />
</div>
<div id="prompt-engineering" class="section level3">
<h3>ğŸ” Prompt Engineering</h3>
<p><strong>DefiniciÃ³n:</strong><br />
TÃ©cnica para diseÃ±ar prompts mÃ¡s efectivos, claros y orientados a la
tarea deseada.</p>
<p><strong>Ejemplo:</strong><br />
Prompt mejorado: &gt; â€œA partir del siguiente texto, indica si el
discurso refleja una polÃ­tica de mano dura. Justifica tu respuesta.
Texto: {discurso}â€</p>
<hr />
</div>
</div>
<div id="en-entorno-de-desarrollo" class="section level2">
<h2>âš™ï¸ En entorno de desarrollo</h2>
<div id="ollama" class="section level3">
<h3>ğŸ’» Ollama</h3>
<p><strong>DefiniciÃ³n:</strong><br />
Herramienta que permite correr modelos LLM localmente en tu computador
(como LLaMA) de forma optimizada.</p>
<p><strong>Ejemplo:</strong><br />
EstÃ¡s usando <code>ollama run llama3.1</code> para hacer inferencia
directamente desde CMD.</p>
<hr />
</div>
<div id="python" class="section level3">
<h3>ğŸ Python</h3>
<p><strong>DefiniciÃ³n:</strong><br />
Lenguaje de programaciÃ³n con el que puedes integrar modelos, procesar
datos y automatizar tu anÃ¡lisis temÃ¡tico.</p>
<p><strong>Ejemplo:</strong><br />
Leer discursos desde Excel, limpiarlos con <code>pandas</code>, y
enviarlos al modelo con una peticiÃ³n vÃ­a <code>subprocess</code> u
<code>Ollama API</code>.</p>
<hr />
</div>
<div id="pandas" class="section level3">
<h3>ğŸ“Š Pandas</h3>
<p><strong>DefiniciÃ³n:</strong><br />
LibrerÃ­a de Python para anÃ¡lisis y manipulaciÃ³n de datos estructurados
(tablas, Excel, CSV).</p>
<p><strong>Ejemplo:</strong><br />
Cargar tu base de discursos en Excel y recorrer cada discurso con un
loop para hacer inferencia.</p>
<hr />
</div>
<div id="transformers-librerÃ­a" class="section level3">
<h3>ğŸ“š Transformers (librerÃ­a)</h3>
<p><strong>DefiniciÃ³n:</strong><br />
LibrerÃ­a de <code>Hugging Face</code> que permite trabajar con miles de
modelos preentrenados. Puedes hacer clasificaciÃ³n, embeddings, QA,
etc.</p>
<p><strong>Ejemplo:</strong><br />
Una vez que lleves el modelo a Python, podÃ©s usar
<code>transformers.pipeline("text-classification")</code> para hacer
clasificaciones automÃ¡ticas.</p>
<hr />
</div>
</div>
<div id="otros-tÃ©rminos-relevantes" class="section level2">
<h2>ğŸ§ª Otros tÃ©rminos relevantes</h2>
<div id="quantization" class="section level3">
<h3>âš™ï¸ Quantization</h3>
<p><strong>DefiniciÃ³n:</strong><br />
TÃ©cnica para reducir el tamaÃ±o de un modelo bajando la precisiÃ³n de los
parÃ¡metros (por ejemplo, de 16 bits a 4 bits).</p>
<p><strong>Ejemplo:</strong><br />
Tu modelo LLaMA 4B probablemente estÃ© cuantizado a 4 bits, lo que
permite correrlo en GPU con 8 GB VRAM.</p>
<hr />
</div>
<div id="lora-low-rank-adaptation" class="section level3">
<h3>ğŸ§  LoRA (Low-Rank Adaptation)</h3>
<p><strong>DefiniciÃ³n:</strong><br />
TÃ©cnica ligera para hacer fine-tuning sin modificar todos los parÃ¡metros
del modelo.</p>
<p><strong>Ejemplo:</strong><br />
PodrÃ­as ajustar tu modelo a discursos chilenos sin necesitar grandes
recursos computacionales.</p>
<hr />
</div>
<div id="zero-shot-few-shot" class="section level3">
<h3>ğŸ“Œ Zero-shot / Few-shot</h3>
<p><strong>DefiniciÃ³n:</strong><br />
- Zero-shot: el modelo responde sin ver ejemplos. - Few-shot: el modelo
recibe 1â€“5 ejemplos en el prompt para â€œaprenderâ€ el patrÃ³n.</p>
<p><strong>Ejemplo:</strong><br />
Zero-shot: â€œÂ¿Este discurso es punitivista?â€<br />
Few-shot: AÃ±ades 2 ejemplos antes del discurso objetivo.</p>
<hr />
</div>
<div id="dataset" class="section level3">
<h3>ğŸ“‚ Dataset</h3>
<p><strong>DefiniciÃ³n:</strong><br />
ColecciÃ³n de datos estructurados que se usa para entrenar o validar
modelos.</p>
<p><strong>Ejemplo:</strong><br />
Tu Excel de discursos es un dataset que podÃ©s usar para clasificaciÃ³n,
fine-tuning o embeddings.</p>
<hr />
</div>
<div id="overfitting" class="section level3">
<h3>ğŸ§  Overfitting</h3>
<p><strong>DefiniciÃ³n:</strong><br />
Cuando el modelo se adapta demasiado a los datos de entrenamiento y
pierde capacidad de generalizar.</p>
<p><strong>Ejemplo:</strong><br />
Si haces fine-tuning con muy pocos discursos, el modelo podrÃ­a funcionar
solo con esos y fallar con nuevos.</p>
<hr />
</div>
<div id="pipeline" class="section level3">
<h3>ğŸ”„ Pipeline</h3>
<p><strong>DefiniciÃ³n:</strong><br />
Secuencia de pasos automatizados para procesar datos, pasarlos por un
modelo, y guardar los resultados.</p>
<p><strong>Ejemplo:</strong><br />
Leer discurso âœ enviar a LLaMA âœ clasificar âœ guardar en Excel âœ
repetir.</p>
<hr />
<p>Â¿Quieres que te prepare ahora la segunda parte: el inicio del
cuaderno con estructura Markdown + ejemplo de flujo para anÃ¡lisis
temÃ¡tico con LLaMA y pandas?</p>
</div>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
